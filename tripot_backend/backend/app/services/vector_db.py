import uuid
import time
import asyncio
from pinecone import Pinecone, ServerlessSpec

# ì„¤ì • íŒŒì¼ê³¼ AI ì„œë¹„ìŠ¤ í•¨ìˆ˜ë¥¼ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
from app.core.config import settings
from . import ai_service # ìˆœí™˜ ì°¸ì¡°ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ai_serviceë¥¼ ë‚˜ì¤‘ì— ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™” í•„ìš”

# Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    pc = Pinecone(api_key=settings.PINECONE_API_KEY)
    
    # ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if settings.PINECONE_INDEX_NAME not in pc.list_indexes().names():
        pc.create_index(
            name=settings.PINECONE_INDEX_NAME, 
            dimension=1536, # OpenAI ì„ë² ë”© ëª¨ë¸ì˜ ì°¨ì› ìˆ˜
            metric="cosine", 
            spec=ServerlessSpec(cloud="aws", region="us-east-1")
        )
    
    index = pc.Index(settings.PINECONE_INDEX_NAME)
    print(f"âœ… Pinecone '{settings.PINECONE_INDEX_NAME}' ì¸ë±ìŠ¤ì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"âŒ Pinecone ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    index = None


async def create_memory_for_pinecone(user_id: str, current_session_log: list):
    """ì„¸ì…˜ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ê±°ë‚˜ ì›ë¬¸ ê·¸ëŒ€ë¡œ Pineconeì— ê¸°ì–µìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    if not index:
        print("Pinecone ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ê¸°ì–µì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ§  [{user_id}] ë‹˜ì˜ ì„¸ì…˜ ê¸°ì–µ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    if not current_session_log: return

    is_short_conversation = len(current_session_log) < 4
    memory_text, memory_type = "", ""

    if is_short_conversation:
        print("-> ì§§ì€ ëŒ€í™”ë¡œ íŒë‹¨, ëŒ€í™” ì›ë¬¸ì„ 'utterance' íƒ€ì…ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
        memory_text = "\n".join(current_session_log)
        memory_type = 'utterance'
    else:
        print("-> ê¸´ ëŒ€í™”ë¡œ íŒë‹¨, í•µì‹¬ ìš”ì•½ì„ 'summary' íƒ€ì…ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        conversation_history = "\n".join(current_session_log)
        summary_prompt = f"""ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì—ì„œ ì‚¬ìš©ìì˜ ì£¼ìš” ê´€ì‹¬ì‚¬, ê°ì •, ì¤‘ìš”í•œ ì •ë³´ ë“±ì„ 1~2 ë¬¸ì¥ì˜ ê°„ê²°í•œ ê¸°ì–µìœ¼ë¡œ ìƒì„±í•´ì¤˜. ê·œì¹™: ì§€ëª…, ì¸ëª… ë“± ëª¨ë“  ê³ ìœ ëª…ì‚¬ëŠ” ë°˜ë“œì‹œ í¬í•¨ì‹œì¼œì•¼ í•´.

--- ëŒ€í™” ë‚´ìš© ---
{conversation_history}
-----------------

í•µì‹¬ ê¸°ì–µ:"""
        memory_text = await ai_service.get_ai_chat_completion(summary_prompt, max_tokens=200, temperature=0.3)
        memory_type = 'summary'

    print(f"ğŸ“ ìƒì„±ëœ ê¸°ì–µ (íƒ€ì…: {memory_type}): {memory_text}")
    embedding = await ai_service.get_embedding(memory_text)
    
    vector_to_upsert = {
        'id': str(uuid.uuid4()), 
        'values': embedding,
        'metadata': {
            'user_id': user_id, 
            'text': memory_text, 
            'timestamp': int(time.time()), 
            'memory_type': memory_type
        }
    }
    await asyncio.to_thread(index.upsert, vectors=[vector_to_upsert])
    print(f"âœ… [{user_id}] ë‹˜ì˜ ìƒˆë¡œìš´ ì„¸ì…˜ ê¸°ì–µì´ Pineconeì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


async def search_memories(user_id: str, query_message: str, top_k=5):
    """ê³¼ê±° ëŒ€í™” ê¸°ì–µì„ ê²€ìƒ‰í•˜ê³  í˜„ì¬ ëŒ€í™”ì™€ì˜ ê´€ë ¨ë„ì— ë”°ë¼ ìˆœìœ„ë¥¼ ë§¤ê²¨ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not index:
        print("Pinecone ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ê¸°ì–µì„ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""
        
    query_embedding = await ai_service.get_embedding(query_message)
    results = await asyncio.to_thread(
        index.query, 
        vector=query_embedding, 
        top_k=top_k, 
        filter={'user_id': user_id}, 
        include_metadata=True
    )
    
    now = int(time.time())
    ranked_memories = []
    if not results['matches']:
        return ""

    for match in results['matches']:
        similarity_score = match['score']
        metadata = match.get('metadata', {})
        timestamp = metadata.get('timestamp', now)
        
        # ì‹œê°„ ê°€ì¤‘ì¹˜ ê³„ì‚° (30ì¼ ì´ë‚´ì˜ ê¸°ì–µì— ë” ë†’ì€ ì ìˆ˜ ë¶€ì—¬)
        time_decay_factor = 30 * 24 * 60 * 60 
        recency_score = max(0, (timestamp - (now - time_decay_factor)) / time_decay_factor)
        
        # ìµœì¢… ì ìˆ˜ = ìœ ì‚¬ë„ 70% + ìµœì‹ ì„± 30%
        final_score = (similarity_score * 0.7) + (recency_score * 0.3)
        ranked_memories.append({'text': metadata.get('text', ''), 'score': final_score})
        
    ranked_memories.sort(key=lambda x: x['score'], reverse=True)
    top_memories = [item['text'] for item in ranked_memories[:3]]
    
    print(f"ğŸ” [{user_id}] ë‹˜ì˜ ê³¼ê±° í•µì‹¬ ê¸°ì–µ {len(top_memories)}ê°œë¥¼ ì¬ì •ë ¬í•˜ì—¬ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.")
    return "\n".join(top_memories)
